<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="stylesheet" href="./css/styles.css" />
  <title>Research</title>
</head>

<body>
  <!-- Research Section -->
  <script src="https://code.jquery.com/jquery-3.3.1.js" integrity="sha256-2Kok7MbOyxpgUVvAk/HJ2jigOSYS2auK4Pfzbm7uH60=" crossorigin="anonymous"></script>
  <script>
    $(function () {
      $("#header").load("header.html");
    });
  </script>
  <div id="header"></div>


<div class="card">
    <div class="card__left">
      <img class="card__left__img" src="images/LLM.png" />
      <h3>Large Language Models</h3>
      <hr />
      <div class="card__left__details">
        <ul>
          <li>LLM Psychometrics </li>
          <li>LLM Jailbreaking</li>
          <li>LLM Interpretability</li>
        </ul>
      </div>
    </div>
    <div class="card__right">
      <div class="card__right__cards">
        <div class="card__right__cards__fullwidthrow2">
          <div>
            <img src="images/LLM_real_world.png" />
            <span class="card__right__cards__row__description">
              <ul>
                <li>LLMs imitate human writing; but how human-like are they?</li>
                <li>Can we hijack LLM's persona and steer it adversarially using just conversational history? If yes, what could be potential risks in real world?</li>
                <li>LLM interpretability to study its persona through the lens of neuroscience.</li>
              </ul>
            </span>
          </div>
        </div>
        <hr />
        <div class="card__right__cards__row2">
          <div>
            <img src="images/LLM_psychometrics.jpg" />
            <span class="card__right__cards__row__description">
              <small style="display: block; text-align: center; font-size: 0.7em"><b>LLM Psychometrics</b></small>
              <ul style="margin-top: -0.5em;">
                 <li>How human-like are LLMs?</li>
                <li>Context-aware personality evaluation framework</li>
                <li>Role-playing agents and persona stability via psychometric evaluation</li>
              </ul>
            </span>
          </div>
          <div>
            <img src="images/PHISH.png" />
            <span class="card__right__cards__row__description">
              <small style="display: block; text-align: center; font-size: 0.7em"><b>LLM Persona Jailbreaking</b></small>
              <ul style="margin-top: -0.5em;">
                <li>Black-box persona editing</li>
                <li>Persona Hijacking via Implicit Steering in History</li>
                <li>A new vulnerability in LLM impacts education, mental health and customer support</li>
              </ul>
            </span>
          </div>
          <div>
            <img src="images/LLM_interpretability.png" />
            <span class="card__right__cards__row__description">
              <small style="display: block; text-align: center; font-size: 0.7em"><b>LLM Interpretability</b></small>
              <ul style="margin-top: -0.5em;">
                <li>How do LLMs get persona?</li>
                <li>Mechanistic interpretability for synthesizing persona</li>
                <li>Understanding mechanisms like in-context learning via neuro-inspired analysis </li>
              </ul>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
  <!--card 2-->
  <div class="card">
    <div class="card__left">
      <img class="card__left__img" src="images/Ai-for-Good-scaled.jpg" />
      <h3>AI for Social Good </h3>
      <hr />
      <div class="card__left__details">
        <ul>
          <li>AI for Healthcare </li>
          <li>AI for Science</li>
          <li>AI for Edge-devices</li>
        </ul>
      </div>
    </div>
    <div class="card__right">
      <div class="card__right__cards">
        <div class="card__right__cards__fullwidthrow2">
          <div>
            <img src="images/AI4good.png" />
            <span class="card__right__cards__row__description">
              <ul>
                <li>Build real world AI applications that solve practical, high-impact problems where utility matters more than flashy demos.</li>
                <li>Convert recent advances in LLMs into deployable tools that strengthen social infrastructure</li>
                <li>Improve human-AI collaboration</li>
              </ul>
            </span>
          </div>
        </div>
        <hr />
        <div class="card__right__cards__row2">
          <div>
            <img src="images/AI_in_Healthcare.png" />
            <span class="card__right__cards__row__description">
              <small style="display: block; text-align: center; font-size: 0.7em"><b>AI for Healthcare</b></small>
              <ul style="margin-top: -0.5em;">
                <li>Rural India still face limited access to healthcare. </li>
                <li> Building assistive AI that scales human doctors without replacing them</li>
                <li>Features: multilingual intake, symptom logging, clinical note drafting, etc.</li>
              </ul>
            </span>
          </div>
           
          <div>
            <img src="images/Ai_peer_review.jpeg" />
            <span class="card__right__cards__row__description">
              <small style="display: block; text-align: center; font-size: 0.7em"><b>AI for Science</b></small>
              <ul style="margin-top: -0.5em;">
                <li>Conference scale makes review guideline adherence difficult to maintain.</li>
                <li>How can AI assist reviewers without replacing them?</li>
                <li>Developing an OpenReview integrated system that supports reviewers.</li>
              </ul>
            </span>
          </div>
          <div>
            <img src="images/AI_mobile.webp" />
            <span class="card__right__cards__row__description">
              <small style="display: block; text-align: center; font-size: 0.7em"><b>AI for Edge-devices</b></small>
              <ul style="margin-top: -0.5em;">
                <li>How to make AI accessible locally for mobile users? 
                </li>
                <li>Developing multilingual, on-device SLM assistants for tasks like messaging, etc.</li>
                <li>Efficiency, privacy-preserving personalization for mobile-first communities.</li>
                
              </ul>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!--card 3-->
  <div class="card">
    <div class="card__left">
      <img class="card__left__img" src="images/cluster.webp" />
      <h3>Representation Learning</h3>
      <!-- <h5>(Digital India)</h5> -->
      <hr />
      <div class="card__left__details">
        <ul>
          <li>Pretraining</li>
          <li>Applications: </li>
          <ul>
          <li>Culture Linguistics</li>
          <li>Image Caption Learning</li></ul>
          
        </ul>
      </div>
    </div>
    <div class="card__right">
      <div class="card__right__cards">
        <div class="card__right__cards__fullwidthrow2">
          <div>
            <img src="images/representation_eng.png" />
            <span class="card__right__cards__row__description">
              <ul>
               <li> Learning structured abstractions: Build latent spaces that capture the essential structure of data: syntax, semantics, vision, or multimodal cues.

              <li>Task-aligned embeddings: Shape representations to encode properties that downstream tasks need, improving generalization and robustness.</li>

              <li>Cross-domain transfer: Use shared representations to transfer knowledge across languages, modalities, or low-resource settings.</li>
              </ul>
            </span>
          </div>
        </div>
        <hr />
        <div class="card__right__cards__row2">
            <div>
            <img src="images/LCM.png" />
            <span class="card__right__cards__row__description">
              <small style="display: block; text-align: center; font-size: 0.7em"><b>Pretraining</b></small>
              <ul style="margin-top: -0.5em;">
                <li>Can we design pretraining methods that don’t rely on massive corpora?</li>
                <li>Crucial, because world’s 7,000+ languages lack data.</li>
                <li>Yes! Light-weight, linguistically guided task-specific pretraining works.</li>
              </ul>
            </span>
          </div>
          <div>
            <img src="images/culture_language.png" />
            <span class="card__right__cards__row__description">
              <small style="display: block; text-align: center; font-size: 0.7em"><b>Cultural Linguistics</b></small>
              <ul style="margin-top: -0.5em;">
                <li>Can we algorithmically quantify cultural proximity among Indian languages?</li>
                <li>It guides cross-lingual culture transfer in NLP.</li>
                <li>Our phono-semantic framework quantifies the cultural distance.</li>
              </ul>
            </span>
          </div>
          <div>
            <img src="images/TAGSIM.png" />
            <span class="card__right__cards__row__description">
              <small style="display: block; text-align: center; font-size: 0.7em"><b>Image Caption Learning</b></small>
              <ul style="margin-top: -0.5em;">
                <li>Can topic pretraining produce more robust image-caption evaluation metrics?</li>
                <li>Lexical metrics fail under paraphrasing, multilinguality, and stylistic variation.</li>
                <li>Solution: TAGSim, a topic-pretrained metric</li>
              </ul>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
    <div class="card">

    <div class="card__left">
      <img class="card__left__img" src="images/SCL.webp" />
      <h3>Sanskrit Computational Linguistics</h3>
      <hr />
        <!-- <h5>(Perception)</h5> -->  
        <div class="card__left__details">
          <ul>
            <li>Deep learning</li>
            <li>Tokenization</li>
            <li>Compound Identification</li>
            <li>Dependency Parsing</li>
            <li>Shloka Recommendation</li>
            <li>Anvaya Generation</li>
            <li>Machine Translation</li>
          </ul>
        </div>
    </div>
    <div class="card__right">
      <div class="card__right__cards__fullwidthrow2">
          <div>
            <img src="images/sanskritshala.png" />
            <span class="card__right__cards__row__description">
              <ul>
               <li>Digitized manuscripts remain inaccessible due to language barriers and loss of nuance in standard translation systems.</li>

              <li>We built deep-learning models that let users assist in classical texts reading.</li>

              <li>These models power SanskritShala, a web-based neural toolkit that preserves grammatical structure while automating analysis for scholars and learners</li>
              </ul>
            </span>
          </div>
        </div>
        <hr />
      <div class="card__right__cards">
        <div class="card__right__cards__row">
          <div>
            
            <img src="images/tokenization.png" />
            <span class="card__right__cards__row__description">
               <small style="display: block; text-align: center; font-size: 0.7em;margin-top: 0.6em;"><b>Tokenization</b></small>
              <ul style="margin-top: -0.5em;">
                <li>Sanskrit word segmentation is hard due to sandhi.</li>
                <li>TransLIST combines linguistic cues with transformers.</li>
                <li>Achieves strong gains over prior state of the art.</li>
              </ul>
            </span>
          </div>
          <div>
            <img src="images/compound.png" />
            <span class="card__right__cards__row__description">
               <small style="display: block; text-align: center; font-size: 0.7em;margin-top: 0.6em;"><b>Compound Identification</b></small>
            
              <ul style="margin-top: -0.5em;">
                <li>Multi-component compounds have nested semantics.</li>
                <li> Proposed dependency-based framework.</li>
                <li> Results: +13.1 F1 gain and 5× faster inference. </li>
              </ul>
            </span>
          </div>
        </div>

        <div class="card__right__cards__row">
          <div>
            <img src="images/dp.png" />
            <span class="card__right__cards__row__description">
               <small style="display: block; text-align: center; font-size: 0.7em;margin-top: 0.6em;"><b>Dependency Parsing</b></small>
          
              <ul style="margin-top: -0.5em;">
                <li>Which low-resource strategies truly generalize across languages and why?</li>
                <li> Systematically evaluate 5 low-resource strategies.</li>
                <li>Proposed model surpasses Sanskrit SOTA parsing.</li>
              </ul>
            </span>
          </div>
          <div>
            <img src="images/shloka_reco.png" />
            <span class="card__right__cards__row__description">
               <small style="display: block; text-align: center; font-size: 0.7em;margin-top: 0.6em;"><b>Shloka Recommendation</b></small>
             
              <ul style="margin-top: -0.5em;">
                <li>Readers need related ślokas sharing similar essence. </li>
                <li> Solution: Interactive śloka recommendation platform.</li>
                <li>Features: Ranked verses, similarity rationale, and visual verse clusters.</li>
              </ul>
            </span>
          </div>
        </div>

        <div class="card__right__cards__row">
          <div>
            <img src="images/anvaya.png" />
            <span class="card__right__cards__row__description">
               <small style="display: block; text-align: center; font-size: 0.7em;margin-top: 0.6em;"><b>Anvaya Generation</b></small>
           
              <ul style="margin-top: -0.5em;">
                <li>Can LLMs Outperform Smaller Seq2Seq Models on Anvaya Task?</li>
                <li> Compare LLMs with task-specific models. </li>
                <li>Our fine-tuned ByT5-Sanskrit model outperforms general-purpose LLMs. </li>
              </ul>
            </span>
          </div>
          <div>
            <img src="images/MT.png" />
            <span class="card__right__cards__row__description">
               <small style="display: block; text-align: center; font-size: 0.7em;margin-top: 0.6em;"><b>Machine Translation</b></small>
              
              <ul style="margin-top: -0.5em;">
                <li>Google Translate underperforms on domain-specific Sanskrit texts.</li>
                <li>We curate multi-domain data, fine-tune LLMs.</li>
                <li>RAG-integrated, linguistically informed LLMs yield better translations.</li>
              </ul>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</body>
</html>